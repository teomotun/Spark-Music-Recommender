{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make necessary package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "artist_data_small.txt contains information about each user's unique artistId and its name. We read the file and create a map with key: artistId and value: artist Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method to split artist Id and its name.\n",
    "def splitArtistName(line):\n",
    "    try:\n",
    "        id, name = line.split(\"\\t\")\n",
    "        return (int(id), name)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Load text file where each line contains artist Id and its name.\n",
    "artistData = sc.textFile(\"artist_data_small.txt\")\n",
    "# Split artist id: name and store in a map. \n",
    "artistData = artistData.map(splitArtistName).filter(lambda x: x!=None).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioScrobbler has provided us with the a file which contains information about an artist's other alias' / misspelled names. We use this information to correct the user-artist information by replacing the aliases by its uniqueId. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load artist correct id and its aliases\n",
    "    2 columns: badid, goodid\n",
    "    known incorrectly spelt artists and the correct artist id. \n",
    "'''\n",
    "artistAlias = sc.textFile('artist_alias_small.txt')\n",
    "# Split Artist Alias data into (badId, goodId)\n",
    "def splitArtistAlias(line):\n",
    "    try:\n",
    "        # Catches error in data\n",
    "        badId, goodId = line.split(\"\\t\")\n",
    "        return (int(badId), int(goodId))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Create map badId: goodId\n",
    "\n",
    "artistAlias = artistAlias.map(splitArtistAlias).filter(lambda x: x!=None).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, user_artist_data_small.txt contains misspelled artistId. Hence we use the artistAlias map to correct the entries in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load data about user's music listening history\n",
    "Each line contains three features: userid, artistid, playcount\n",
    "'''\n",
    "userArtistData = sc.textFile(\"user_artist_data_small.txt\")\n",
    "\n",
    "# Return the corrected user information.\n",
    "def parseUserHistory(line):\n",
    "    try:\n",
    "        # Catch error in line\n",
    "        user, artist, count = line.split()\n",
    "        # Return the corrected user information.\n",
    "        if artist in artistAlias:\n",
    "            return (int(user), artistAlias[artist], int(count))\n",
    "        else:\n",
    "            return (int(user), int(artist), int(count))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create corrected user history RDD.\n",
    "userArtistData = userArtistData.map(parseUserHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since userArtistData would be used repeatedly, we might want to cache this to avoid re-computation of the same RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userArtistData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section creates a new RDD containing basic user listening stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userArtistPurge = userArtistData.map(lambda x: (x[0],x[2]))\n",
    "# Create an RDD storing user information in the form of (total play count of all artists combined for the current user, (userId of the current user, number of unique artists listened by user))\n",
    "songCountAgg = userArtistPurge.aggregateByKey((0,0), lambda a,b: (a[0] + b, a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1])).map(lambda x: (x[1][0], (x[0], x[1][1])))\n",
    "# Sort the RDD based on the total play counts so as to find the most active user.\n",
    "sortedCount = songCountAgg.sortByKey(False)\n",
    "# Find the top 3 user information\n",
    "sortedCountTop3 = sortedCount.take(3)\n",
    "\n",
    "# Print the top 3 user information.\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[0][1][0],sortedCountTop3[0][0], sortedCountTop3[0][0]/sortedCountTop3[0][1][1])\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[1][1][0],sortedCountTop3[1][0], sortedCountTop3[1][0]/sortedCountTop3[1][1][1])\n",
    "\n",
    "print \"User %s has a total play count of %d and a mean play count of %s\" %(sortedCountTop3[2][1][0],sortedCountTop3[2][0], sortedCountTop3[2][0]/sortedCountTop3[2][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "    User 1059637 has a total play count of 674412 and a mean play count of 1878\n",
    "\n",
    "    User 2064012 has a total play count of 548427 and a mean play count of 9455\n",
    "\n",
    "    User 2069337 has a total play count of 393515 and a mean play count of 1519\n",
    "\n",
    "Split the dataset into 3 parts, trainingData, validationData and testData in the ratio of 4:4:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData, validationData, testData = userArtistData.randomSplit([0.4,0.4,0.2], seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these dataset would be used repeatedly, we might want to cache this to avoid re-computation of the same RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we define a method which would evaluate the accuracy of the model based on the validation set. Instead of the common mean squared error which can be defined as (MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) in python, we define our own error function. In our error function we calculate the fraction of the overlapping artists between the predicted artists/ true artists. We then sum this fraction for all users and the final score is the sum normalized by the total number of users. In our evaluation model, we purge out all the arists listed in the training Data for that particular user while making the top-K predictions, to reduce the bias in error estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelEval(model, data):\n",
    "    artistsList =  broadcastVar.value\n",
    "    total = 0.0\n",
    "    userList = validationData.map(lambda x: x[0]).distinct().collect()\n",
    "    for user in users:\n",
    "        trainArtists = set(trainData.filter(lambda x: x[0]==userList).map(lambda x: x[1]).collect())\n",
    "        #Remove artists for the current user in training Dataset from the userArtistData.\n",
    "        nonTrainArtists = sc.parallelize([(user,artist) for artist in artistsList if not artist in trainArtists])\n",
    "        #use the model to predict all the ratings on nonTrainArtists\n",
    "        prediction = model.predictAll(nonTrainArtists)\n",
    "        #top X sorted by highest rating from the prediction for the current user\n",
    "        X = len(trueArtists)\n",
    "        topX = sorted(prediction.collect(), key=lambda x: x.rating, reverse=True)[:X]\n",
    "        \n",
    "        trueArtists = set(data.filter(lambda x: x[0]==userList).map(lambda x: x[1]).collect())\n",
    "        topArtist = set(topX.map(lambda x: x[1]))\n",
    "        #Compare predictResult to trueArtists\n",
    "        total += float(len(topArtist & trueArtists))/len(trueArtists)\n",
    "    return total/len(userList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will fetch all the distinct artistIDs. Since the allArtist list is huge in size and would be sent to multiple node clusters, many times, it would make sense to broadcast the variable which would send it to all the node clusters and their respective partitions once and cache them for reusablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allArtists = userArtistData.map(lambda x: x[1]).distinct().collect()\n",
    "broadcastVar = sc.broadcast(allArtists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we evaluate our model on the validation dataset based on different rank parameters. The rank parameter corresponds to the number of latent factors in the matrix factorization of the ALS algorithm. Hence we run the model for different rank parameter and then we choose the one which yielded the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the model accuracy score \n",
    "for val in [2, 10, 20]:\n",
    "    model = ALS.trainImplicit(training, rank=val, seed=345)\n",
    "    print(\"The model score for rank %d is %f\" % (rank, modelEval(model, validationData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "    The model score for rank 2 is 0.090323\n",
    "    The model score for rank 10 is 0.095194\n",
    "    The model score for rank 20 is 0.091957\n",
    "\n",
    "We choose the model which yielded the highest accuracy as our final model to make recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestModel = ALS.trainImplicit(trainData, rank=10, seed=345)\n",
    "modelEval(bestModel, testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is ready to make recommendations.  We now make top 5 artist recommendations for user 1059637. The function recommendProducts takes userId as the first input parameter and an integer n, while returning the top n highest ranked recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top5=bestModel.recommendProducts(1059637, 5)\n",
    "i=1\n",
    "for val in top5:\n",
    "    print \"Artist %d : %s\" %(i,dictionary[val[1]])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "    \n",
    "    Artist 1: Taking Back Sunday\n",
    "    Artist 2: Evanescence\n",
    "    Artist 3: Elliott Smith\n",
    "    Artist 4: blink-182\n",
    "    Artist 5: Brand New"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
